{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Global parameters\n","metadata":{}},{"cell_type":"code","source":"years = [2016,2017,2018]\nzone = 'NW'\n\n# How many stations we take to predict temperature in the area between them\naround = 10 \n\n# The initial station from which we start\nSTATION = 14066001\n\nmindist = 10","metadata":{"execution":{"iopub.status.busy":"2022-05-23T16:38:42.509156Z","iopub.execute_input":"2022-05-23T16:38:42.509554Z","iopub.status.idle":"2022-05-23T16:38:42.538959Z","shell.execute_reply.started":"2022-05-23T16:38:42.50943Z","shell.execute_reply":"2022-05-23T16:38:42.538269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\n    '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T16:38:42.540406Z","iopub.execute_input":"2022-05-23T16:38:42.540785Z","iopub.status.idle":"2022-05-23T16:38:42.554682Z","shell.execute_reply.started":"2022-05-23T16:38:42.540746Z","shell.execute_reply":"2022-05-23T16:38:42.553612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting and pre-processing data from kaggle datasets\n## Step one","metadata":{}},{"cell_type":"code","source":"fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(2016)+'.csv'\ndf = pd.read_csv(fname)\n\n# this dataframe we need to get closest stations from STATION\nnew_df = df.drop(['height_sta','date','dd','ff','precip','hu','td','t','psl'],axis=1)\\\n    .drop_duplicates('number_sta').reset_index()\n    \nlat = new_df[new_df.number_sta==STATION].lat.values[0]\nlon = new_df[new_df.number_sta==STATION].lon.values[0]\n    \n    \n# Arrays of closest stations\nneighbours= np.zeros(around)\nneighbours[0] = STATION\n    \nfor station in range(1,around):\n    for i in range(0,new_df.shape[0]):\n        if new_df.loc[i]['number_sta'] not in neighbours:\n            currdist = np.abs(lat - new_df.loc[i].lat) + np.abs(lon-new_df.loc[i].lon)\n            if(mindist > currdist):\n                mindist = currdist\n                index = i\n    neighbours[station]=new_df.loc[index]['number_sta']\n    mindist=10\n    \ndel new_df\n\ndel df","metadata":{"execution":{"iopub.status.busy":"2022-05-23T16:38:42.555937Z","iopub.execute_input":"2022-05-23T16:38:42.556172Z","iopub.status.idle":"2022-05-23T16:39:29.796969Z","shell.execute_reply.started":"2022-05-23T16:38:42.556141Z","shell.execute_reply":"2022-05-23T16:39:29.796041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather = pd.DataFrame()\nfor year in years:\n    fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(year)+'.csv'\n    df = pd.read_csv(fname)\n    \n    # Getting source data from stations in neighbours\n    for i in range(0,around):\n        dataframe = df[(df['number_sta'] == int(neighbours[i]))]\n        weather = weather.append(dataframe,ignore_index = True)\n    \n    del df\n    \n    del dataframe","metadata":{"execution":{"iopub.status.busy":"2022-05-23T16:39:29.798701Z","iopub.execute_input":"2022-05-23T16:39:29.798967Z","iopub.status.idle":"2022-05-23T16:41:42.972284Z","shell.execute_reply.started":"2022-05-23T16:39:29.798932Z","shell.execute_reply":"2022-05-23T16:41:42.970668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-23T16:41:42.974498Z","iopub.execute_input":"2022-05-23T16:41:42.974934Z","iopub.status.idle":"2022-05-23T16:41:43.019174Z","shell.execute_reply.started":"2022-05-23T16:41:42.974888Z","shell.execute_reply":"2022-05-23T16:41:43.018459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.drop_duplicates('number_sta')","metadata":{"execution":{"iopub.status.busy":"2022-05-23T16:41:55.498029Z","iopub.execute_input":"2022-05-23T16:41:55.498921Z","iopub.status.idle":"2022-05-23T16:41:55.622223Z","shell.execute_reply.started":"2022-05-23T16:41:55.49887Z","shell.execute_reply":"2022-05-23T16:41:55.621527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling na by bfill groupped data by number_sta","metadata":{}},{"cell_type":"code","source":"weather.date = pd.to_datetime(weather.date)\nweather = weather.sort_values('number_sta').reset_index().drop('index',axis=1)\nweather = weather.fillna(method = 'bfill')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:19.005041Z","iopub.execute_input":"2022-05-16T20:14:19.005802Z","iopub.status.idle":"2022-05-16T20:14:19.97925Z","shell.execute_reply.started":"2022-05-16T20:14:19.005763Z","shell.execute_reply":"2022-05-16T20:14:19.978324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather = weather.sort_values('date').reset_index().drop('index',axis=1)\nprint(weather.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:19.980657Z","iopub.execute_input":"2022-05-16T20:14:19.980877Z","iopub.status.idle":"2022-05-16T20:14:20.502699Z","shell.execute_reply.started":"2022-05-16T20:14:19.980851Z","shell.execute_reply":"2022-05-16T20:14:20.501273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.5042Z","iopub.execute_input":"2022-05-16T20:14:20.504511Z","iopub.status.idle":"2022-05-16T20:14:20.513278Z","shell.execute_reply.started":"2022-05-16T20:14:20.504466Z","shell.execute_reply":"2022-05-16T20:14:20.512485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## taking part from dataset","metadata":{}},{"cell_type":"code","source":"dataset = weather[weather['date']<'2019-01-01']\nprint(dataset.shape)\nprint(dataset.head())\ndel weather","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.514536Z","iopub.execute_input":"2022-05-16T20:14:20.514924Z","iopub.status.idle":"2022-05-16T20:14:20.558385Z","shell.execute_reply.started":"2022-05-16T20:14:20.514892Z","shell.execute_reply":"2022-05-16T20:14:20.557261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Перенос координат в координаты нужной нам станции","metadata":{}},{"cell_type":"code","source":"lat = dataset[dataset['number_sta']==STATION]['lat'].unique()[0]\nlon = dataset[dataset['number_sta']==STATION]['lon'].unique()[0]\n\ndataset['lat'] = dataset['lat']-lat\ndataset['lon'] = dataset['lon']-lon","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.560798Z","iopub.execute_input":"2022-05-16T20:14:20.561325Z","iopub.status.idle":"2022-05-16T20:14:20.578894Z","shell.execute_reply.started":"2022-05-16T20:14:20.561268Z","shell.execute_reply":"2022-05-16T20:14:20.577852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.580274Z","iopub.execute_input":"2022-05-16T20:14:20.580662Z","iopub.status.idle":"2022-05-16T20:14:20.6018Z","shell.execute_reply.started":"2022-05-16T20:14:20.580625Z","shell.execute_reply":"2022-05-16T20:14:20.600548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split date to year, yday, hour, minute","metadata":{}},{"cell_type":"code","source":"dataset['year'] = dataset.date.dt.year\ndataset['yday'] = dataset.date.dt.dayofyear\n\ndataset['hour'] = dataset.date.dt.hour\ndataset['minute'] = dataset.date.dt.minute","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.604906Z","iopub.execute_input":"2022-05-16T20:14:20.605401Z","iopub.status.idle":"2022-05-16T20:14:20.653436Z","shell.execute_reply.started":"2022-05-16T20:14:20.605283Z","shell.execute_reply":"2022-05-16T20:14:20.652766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.654579Z","iopub.execute_input":"2022-05-16T20:14:20.654943Z","iopub.status.idle":"2022-05-16T20:14:20.674615Z","shell.execute_reply.started":"2022-05-16T20:14:20.654914Z","shell.execute_reply":"2022-05-16T20:14:20.673701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling nan by bfill groupped data by date","metadata":{}},{"cell_type":"code","source":"dataset = dataset.set_index('date')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.67603Z","iopub.execute_input":"2022-05-16T20:14:20.676455Z","iopub.status.idle":"2022-05-16T20:14:20.691911Z","shell.execute_reply.started":"2022-05-16T20:14:20.676412Z","shell.execute_reply":"2022-05-16T20:14:20.690962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Можно заполнить значения станции через среднее значений следущего и предыдущего временного этапа этой же станции.. А если и они nan, то по количеству и качеству каждой станции в округе( чем дальше она тем несущественнее ее результат сказывается)","metadata":{}},{"cell_type":"code","source":"# def fill_na_by_mean(dataset,param):\n#     #print(dataset['number_sta'].unique())\n#     stations = dataset['number_sta'].unique()\n#     for station in stations:\n#         for index in range(len(dataset[dataset['number_sta']==station])-5):\n#             if np.isnan(dataset[dataset['number_sta']==station].iloc[index][param]):\n#                 i=1\n#                 numb=0\n#                 while np.isnan(dataset[dataset['number_sta']==station].iloc[index-i][param]) and numb<5:\n#                     i=+1\n#                     numb+=1\n#                 if numb<5:\n#                     first = dataset[dataset['number_sta']==station].iloc[index-i][param]\n#                 else:\n#                     break\n                \n#                 i=1\n#                 numb=0\n#                 while np.isnan(dataset[dataset['number_sta']==station].iloc[index+i][param]) and numb<5:\n#                     i=+1\n#                     numb+=1\n#                 if numb<5:\n#                     second = dataset[dataset['number_sta']==station].iloc[index-i][param]\n#                 else:\n#                     break\n        \n#                 dataset[dataset['number_sta']==station].loc[index][param] = (first+second)/2\n#     return dataset  \n\n# fill_na_by_mean(dataset,'t')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.693221Z","iopub.execute_input":"2022-05-16T20:14:20.693586Z","iopub.status.idle":"2022-05-16T20:14:20.701086Z","shell.execute_reply.started":"2022-05-16T20:14:20.693555Z","shell.execute_reply":"2022-05-16T20:14:20.700025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.fillna(method = 'bfill')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.70231Z","iopub.execute_input":"2022-05-16T20:14:20.70316Z","iopub.status.idle":"2022-05-16T20:14:20.718277Z","shell.execute_reply.started":"2022-05-16T20:14:20.703119Z","shell.execute_reply":"2022-05-16T20:14:20.717608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.71974Z","iopub.execute_input":"2022-05-16T20:14:20.720432Z","iopub.status.idle":"2022-05-16T20:14:20.735081Z","shell.execute_reply.started":"2022-05-16T20:14:20.720394Z","shell.execute_reply":"2022-05-16T20:14:20.734139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:20.736577Z","iopub.execute_input":"2022-05-16T20:14:20.736898Z","iopub.status.idle":"2022-05-16T20:14:20.743303Z","shell.execute_reply.started":"2022-05-16T20:14:20.736865Z","shell.execute_reply":"2022-05-16T20:14:20.742357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizating data...","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T08:57:44.70773Z","iopub.execute_input":"2022-05-18T08:57:44.708133Z","iopub.status.idle":"2022-05-18T08:57:44.716329Z","shell.execute_reply.started":"2022-05-18T08:57:44.708097Z","shell.execute_reply":"2022-05-18T08:57:44.715802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['dd'] = scaler.fit_transform(dataset['dd'].values.reshape(-1,1))\ndataset['ff'] = scaler.fit_transform(dataset['ff'].values.reshape(-1,1))\ndataset['precip'] = scaler.fit_transform(dataset['precip'].values.reshape(-1,1))\ndataset['hu'] = scaler.fit_transform(dataset['hu'].values.reshape(-1,1))\ndataset['td'] = scaler.fit_transform(dataset['td'].values.reshape(-1,1))\ndataset['psl'] = scaler.fit_transform(dataset['psl'].values.reshape(-1,1))\ndataset['t'] = scaler.fit_transform(dataset['t'].values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:21.929645Z","iopub.execute_input":"2022-05-16T20:14:21.93014Z","iopub.status.idle":"2022-05-16T20:14:21.948184Z","shell.execute_reply.started":"2022-05-16T20:14:21.930093Z","shell.execute_reply":"2022-05-16T20:14:21.94754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:21.949441Z","iopub.execute_input":"2022-05-16T20:14:21.95004Z","iopub.status.idle":"2022-05-16T20:14:21.973248Z","shell.execute_reply.started":"2022-05-16T20:14:21.950004Z","shell.execute_reply":"2022-05-16T20:14:21.972439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:21.974615Z","iopub.execute_input":"2022-05-16T20:14:21.974991Z","iopub.status.idle":"2022-05-16T20:14:21.98198Z","shell.execute_reply.started":"2022-05-16T20:14:21.97489Z","shell.execute_reply":"2022-05-16T20:14:21.981117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:21.983486Z","iopub.execute_input":"2022-05-16T20:14:21.984547Z","iopub.status.idle":"2022-05-16T20:14:22.169735Z","shell.execute_reply.started":"2022-05-16T20:14:21.98448Z","shell.execute_reply":"2022-05-16T20:14:22.168801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.reset_index().drop(['date','year','minute','number_sta'],axis=1).corr()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:22.171158Z","iopub.execute_input":"2022-05-16T20:14:22.171454Z","iopub.status.idle":"2022-05-16T20:14:22.232292Z","shell.execute_reply.started":"2022-05-16T20:14:22.171403Z","shell.execute_reply":"2022-05-16T20:14:22.231472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data = dataset.reset_index().drop(['date','year','minute','number_sta'],axis = 1).corr())","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:22.233565Z","iopub.execute_input":"2022-05-16T20:14:22.234486Z","iopub.status.idle":"2022-05-16T20:14:22.658435Z","shell.execute_reply.started":"2022-05-16T20:14:22.234439Z","shell.execute_reply":"2022-05-16T20:14:22.65739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготавливаем датасет к обучению\n\n## Количество X может быть не равно y; Надо проверять есть ли за этот период запись в 'y' и только тогда добавлять X, чтобы их количество было равное","metadata":{}},{"cell_type":"code","source":"def make_tensors(table,predicted_par):\n    \n    data = []\n    target = []\n\n    periods = table.index.unique().astype('str')\n    \n    label = table[table.number_sta==STATION][predicted_par]\n    target = label.values.tolist()\n    \n    #new_table = table.loc[table['number_sta'] != STATION].drop(['td','lat','lon','height_sta','precip','dd','ff','hu','psl','yday','year','hour','minute','number_sta'],axis=1)\n    new_table = table.loc[table['number_sta'] != STATION].drop(['height_sta','year','yday','hour','minute','number_sta'],axis=1)\n    \n    for period in periods:\n        if period in label:\n            data.append(new_table[period:period].values.tolist())\n\n    return data,target","metadata":{"execution":{"iopub.status.busy":"2022-05-18T09:01:57.078848Z","iopub.execute_input":"2022-05-18T09:01:57.079138Z","iopub.status.idle":"2022-05-18T09:01:57.086332Z","shell.execute_reply.started":"2022-05-18T09:01:57.079107Z","shell.execute_reply":"2022-05-18T09:01:57.085393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X,y = make_tensors(dataset,'t')","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:22.668026Z","iopub.execute_input":"2022-05-16T20:14:22.668566Z","iopub.status.idle":"2022-05-16T20:14:34.358191Z","shell.execute_reply.started":"2022-05-16T20:14:22.668463Z","shell.execute_reply":"2022-05-16T20:14:34.357325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:34.359582Z","iopub.execute_input":"2022-05-16T20:14:34.359868Z","iopub.status.idle":"2022-05-16T20:14:34.366945Z","shell.execute_reply.started":"2022-05-16T20:14:34.359831Z","shell.execute_reply":"2022-05-16T20:14:34.36588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:34.369353Z","iopub.execute_input":"2022-05-16T20:14:34.369736Z","iopub.status.idle":"2022-05-16T20:14:34.382383Z","shell.execute_reply.started":"2022-05-16T20:14:34.369693Z","shell.execute_reply":"2022-05-16T20:14:34.381103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:34.390109Z","iopub.execute_input":"2022-05-16T20:14:34.39039Z","iopub.status.idle":"2022-05-16T20:14:34.396198Z","shell.execute_reply.started":"2022-05-16T20:14:34.390361Z","shell.execute_reply":"2022-05-16T20:14:34.395427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Делаем Х_ полным для 9 станций по 5 зависимым столбцам каждый\n## а остальные не берем в датасет","metadata":{}},{"cell_type":"code","source":"columns = len(X[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:34.39738Z","iopub.execute_input":"2022-05-16T20:14:34.397704Z","iopub.status.idle":"2022-05-16T20:14:34.408523Z","shell.execute_reply.started":"2022-05-16T20:14:34.397671Z","shell.execute_reply":"2022-05-16T20:14:34.407803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_ = np.empty((0,(around-1)*columns),dtype='f')\nindex = []\nfor i in range(len(X)):\n    if len([a for b in X[i] for a in b]) == (around-1)*columns and i!=len(X)-1:\n        X_= np.append(X_,[[a for b in X[i] for a in b]],axis=0)\n    else:\n        index.append(i)\n\nindex.pop(len(index)-1)\n\ny=np.delete(y,index,None)\ny = np.delete(y,len(y)-1,None)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:34.409538Z","iopub.execute_input":"2022-05-16T20:14:34.409787Z","iopub.status.idle":"2022-05-16T20:14:36.204491Z","shell.execute_reply.started":"2022-05-16T20:14:34.409753Z","shell.execute_reply":"2022-05-16T20:14:36.203733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.205853Z","iopub.execute_input":"2022-05-16T20:14:36.206051Z","iopub.status.idle":"2022-05-16T20:14:36.211758Z","shell.execute_reply.started":"2022-05-16T20:14:36.206027Z","shell.execute_reply":"2022-05-16T20:14:36.210936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.212982Z","iopub.execute_input":"2022-05-16T20:14:36.213184Z","iopub.status.idle":"2022-05-16T20:14:36.22833Z","shell.execute_reply.started":"2022-05-16T20:14:36.213159Z","shell.execute_reply":"2022-05-16T20:14:36.227491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_ = [[] for k in range(len(y))]\nfor i in range(len(y)):\n    y_[i] = [y[i]]\nprint(len(y_))\ny = y_","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.229716Z","iopub.execute_input":"2022-05-16T20:14:36.230227Z","iopub.status.idle":"2022-05-16T20:14:36.241787Z","shell.execute_reply.started":"2022-05-16T20:14:36.230183Z","shell.execute_reply":"2022-05-16T20:14:36.241147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.24265Z","iopub.execute_input":"2022-05-16T20:14:36.243476Z","iopub.status.idle":"2022-05-16T20:14:36.259038Z","shell.execute_reply.started":"2022-05-16T20:14:36.243441Z","shell.execute_reply":"2022-05-16T20:14:36.258056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.261538Z","iopub.execute_input":"2022-05-16T20:14:36.261863Z","iopub.status.idle":"2022-05-16T20:14:36.284711Z","shell.execute_reply.started":"2022-05-16T20:14:36.261823Z","shell.execute_reply":"2022-05-16T20:14:36.283791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Разделение датасета на тестовую и тренировочную части","metadata":{}},{"cell_type":"code","source":"X_train = X_[0:int(len(X_)*0.9)]\nX_test = X_[int(len(X_)*0.9):]\n\ny_train = y[0:int(len(y)*0.9)]\ny_test = y[int(len(y)*0.9):]","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.286122Z","iopub.execute_input":"2022-05-16T20:14:36.286672Z","iopub.status.idle":"2022-05-16T20:14:36.297413Z","shell.execute_reply.started":"2022-05-16T20:14:36.286639Z","shell.execute_reply":"2022-05-16T20:14:36.296801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.2, random_state=39)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.299167Z","iopub.execute_input":"2022-05-16T20:14:36.299764Z","iopub.status.idle":"2022-05-16T20:14:36.310783Z","shell.execute_reply.started":"2022-05-16T20:14:36.299722Z","shell.execute_reply":"2022-05-16T20:14:36.309889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.312101Z","iopub.execute_input":"2022-05-16T20:14:36.312427Z","iopub.status.idle":"2022-05-16T20:14:36.325225Z","shell.execute_reply.started":"2022-05-16T20:14:36.3124Z","shell.execute_reply":"2022-05-16T20:14:36.324336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.326547Z","iopub.execute_input":"2022-05-16T20:14:36.326862Z","iopub.status.idle":"2022-05-16T20:14:36.339741Z","shell.execute_reply.started":"2022-05-16T20:14:36.326823Z","shell.execute_reply":"2022-05-16T20:14:36.338994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.341161Z","iopub.execute_input":"2022-05-16T20:14:36.343277Z","iopub.status.idle":"2022-05-16T20:14:36.354114Z","shell.execute_reply.started":"2022-05-16T20:14:36.343233Z","shell.execute_reply":"2022-05-16T20:14:36.353152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:36.355254Z","iopub.execute_input":"2022-05-16T20:14:36.356135Z","iopub.status.idle":"2022-05-16T20:14:36.367242Z","shell.execute_reply.started":"2022-05-16T20:14:36.356096Z","shell.execute_reply":"2022-05-16T20:14:36.366577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-05-18T09:05:53.283571Z","iopub.execute_input":"2022-05-18T09:05:53.284462Z","iopub.status.idle":"2022-05-18T09:05:54.594845Z","shell.execute_reply.started":"2022-05-18T09:05:53.28437Z","shell.execute_reply":"2022-05-18T09:05:54.594019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = torch.from_numpy(X_train).type(torch.Tensor)\nX_test = torch.from_numpy(X_test).type(torch.Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:37.802055Z","iopub.execute_input":"2022-05-16T20:14:37.802605Z","iopub.status.idle":"2022-05-16T20:14:37.839142Z","shell.execute_reply.started":"2022-05-16T20:14:37.802557Z","shell.execute_reply":"2022-05-16T20:14:37.838353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = torch.from_numpy(np.array(y_train)).type(torch.Tensor)\ny_test = torch.from_numpy(np.array(y_test)).type(torch.Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:37.840371Z","iopub.execute_input":"2022-05-16T20:14:37.840602Z","iopub.status.idle":"2022-05-16T20:14:37.849643Z","shell.execute_reply.started":"2022-05-16T20:14:37.840576Z","shell.execute_reply":"2022-05-16T20:14:37.84886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Само обучение**","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 40) \n        self.hidden_fc = nn.Linear(40, 20) \n        self.output_fc = nn.Linear(20, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc(h_1)) \n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_2) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-18T11:57:05.030943Z","iopub.execute_input":"2022-05-18T11:57:05.031257Z","iopub.status.idle":"2022-05-18T11:57:05.041888Z","shell.execute_reply.started":"2022-05-18T11:57:05.031222Z","shell.execute_reply":"2022-05-18T11:57:05.040834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:37.865238Z","iopub.execute_input":"2022-05-16T20:14:37.8656Z","iopub.status.idle":"2022-05-16T20:14:37.897517Z","shell.execute_reply.started":"2022-05-16T20:14:37.865571Z","shell.execute_reply":"2022-05-16T20:14:37.896785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:37.898381Z","iopub.execute_input":"2022-05-16T20:14:37.899154Z","iopub.status.idle":"2022-05-16T20:14:37.903095Z","shell.execute_reply.started":"2022-05-16T20:14:37.899114Z","shell.execute_reply":"2022-05-16T20:14:37.902278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:37.904147Z","iopub.execute_input":"2022-05-16T20:14:37.904459Z","iopub.status.idle":"2022-05-16T20:14:38.509966Z","shell.execute_reply.started":"2022-05-16T20:14:37.904432Z","shell.execute_reply":"2022-05-16T20:14:38.509254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.510966Z","iopub.execute_input":"2022-05-16T20:14:38.511858Z","iopub.status.idle":"2022-05-16T20:14:38.515855Z","shell.execute_reply.started":"2022-05-16T20:14:38.511819Z","shell.execute_reply":"2022-05-16T20:14:38.514973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\n\nax = sns.lineplot(data=hist, color='royalblue')\nax.set_xlabel(\"Epoch\", size = 14)\nax.set_ylabel(\"Loss\", size = 14)\nax.set_title(\"Training Loss\", size = 14, fontweight='bold')\nfig.set_figheight(6)\nfig.set_figwidth(16)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.517226Z","iopub.execute_input":"2022-05-16T20:14:38.51757Z","iopub.status.idle":"2022-05-16T20:14:38.765681Z","shell.execute_reply.started":"2022-05-16T20:14:38.517527Z","shell.execute_reply":"2022-05-16T20:14:38.764575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = model(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.766724Z","iopub.execute_input":"2022-05-16T20:14:38.766929Z","iopub.status.idle":"2022-05-16T20:14:38.771228Z","shell.execute_reply.started":"2022-05-16T20:14:38.766905Z","shell.execute_reply":"2022-05-16T20:14:38.770596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.772241Z","iopub.execute_input":"2022-05-16T20:14:38.772959Z","iopub.status.idle":"2022-05-16T20:14:38.785839Z","shell.execute_reply.started":"2022-05-16T20:14:38.772927Z","shell.execute_reply":"2022-05-16T20:14:38.785215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.786994Z","iopub.execute_input":"2022-05-16T20:14:38.787739Z","iopub.status.idle":"2022-05-16T20:14:38.797571Z","shell.execute_reply.started":"2022-05-16T20:14:38.787697Z","shell.execute_reply":"2022-05-16T20:14:38.796929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_predict.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.798873Z","iopub.execute_input":"2022-05-16T20:14:38.799316Z","iopub.status.idle":"2022-05-16T20:14:38.814847Z","shell.execute_reply.started":"2022-05-16T20:14:38.799275Z","shell.execute_reply":"2022-05-16T20:14:38.814232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:38.816318Z","iopub.execute_input":"2022-05-16T20:14:38.816822Z","iopub.status.idle":"2022-05-16T20:14:39.153034Z","shell.execute_reply.started":"2022-05-16T20:14:38.816782Z","shell.execute_reply":"2022-05-16T20:14:39.152384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:39.155252Z","iopub.execute_input":"2022-05-16T20:14:39.155658Z","iopub.status.idle":"2022-05-16T20:14:41.326243Z","shell.execute_reply.started":"2022-05-16T20:14:39.155622Z","shell.execute_reply":"2022-05-16T20:14:41.32523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics","metadata":{}},{"cell_type":"code","source":"y_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:41.3276Z","iopub.execute_input":"2022-05-16T20:14:41.327891Z","iopub.status.idle":"2022-05-16T20:14:41.33344Z","shell.execute_reply.started":"2022-05-16T20:14:41.327847Z","shell.execute_reply":"2022-05-16T20:14:41.332843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:41.334576Z","iopub.execute_input":"2022-05-16T20:14:41.335106Z","iopub.status.idle":"2022-05-16T20:14:41.40199Z","shell.execute_reply.started":"2022-05-16T20:14:41.335065Z","shell.execute_reply":"2022-05-16T20:14:41.401288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:41.404913Z","iopub.execute_input":"2022-05-16T20:14:41.405233Z","iopub.status.idle":"2022-05-16T20:14:41.420281Z","shell.execute_reply.started":"2022-05-16T20:14:41.405192Z","shell.execute_reply":"2022-05-16T20:14:41.419475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Вторая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 45) \n        self.hidden_fc = nn.Linear(45, 15) \n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc(h_1)) \n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_2) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:41.42159Z","iopub.execute_input":"2022-05-16T20:14:41.421821Z","iopub.status.idle":"2022-05-16T20:14:42.566535Z","shell.execute_reply.started":"2022-05-16T20:14:41.421793Z","shell.execute_reply":"2022-05-16T20:14:42.565575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Третья модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 45) \n        self.hidden_fc1 = nn.Linear(45, 30) \n        self.hidden_fc2 = nn.Linear(30, 15) \n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_3) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:42.568207Z","iopub.execute_input":"2022-05-16T20:14:42.568737Z","iopub.status.idle":"2022-05-16T20:14:43.685209Z","shell.execute_reply.started":"2022-05-16T20:14:42.568687Z","shell.execute_reply":"2022-05-16T20:14:43.684591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Четвертая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 30) \n        self.hidden_fc2 = nn.Linear(30, 20)\n        self.hidden_fc3 = nn.Linear(20, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3))\n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_4) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:43.68644Z","iopub.execute_input":"2022-05-16T20:14:43.686997Z","iopub.status.idle":"2022-05-16T20:14:44.839806Z","shell.execute_reply.started":"2022-05-16T20:14:43.686962Z","shell.execute_reply":"2022-05-16T20:14:44.83892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Пятая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 48) \n        self.hidden_fc1 = nn.Linear(48, 37) \n        self.hidden_fc2 = nn.Linear(37, 26)\n        self.hidden_fc3 = nn.Linear(26, 19)\n        \n        self.hidden_fc4 = nn.Linear(19, 8)\n        self.output_fc = nn.Linear(8, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3))\n        \n        h_5 = torch.tanh(self.hidden_fc4(h_4))\n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_5) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:44.841345Z","iopub.execute_input":"2022-05-16T20:14:44.841571Z","iopub.status.idle":"2022-05-16T20:14:46.072698Z","shell.execute_reply.started":"2022-05-16T20:14:44.841544Z","shell.execute_reply":"2022-05-16T20:14:46.071628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Шестая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 40) \n        self.hidden_fc1 = nn.Linear(40, 30) \n        self.hidden_fc2 = nn.Linear(30, 15)\n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_3) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:46.074159Z","iopub.execute_input":"2022-05-16T20:14:46.074403Z","iopub.status.idle":"2022-05-16T20:14:47.087881Z","shell.execute_reply.started":"2022-05-16T20:14:46.074372Z","shell.execute_reply":"2022-05-16T20:14:47.086906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Седьмая модель\n","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 40) \n        self.hidden_fc2 = nn.Linear(40, 30)\n        \n        self.hidden_fc3 = nn.Linear(30, 20)\n        \n        self.hidden_fc4 = nn.Linear(20, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3)) \n    \n        h_5 = torch.tanh(self.hidden_fc4(h_4)) \n        \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_5) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:47.089179Z","iopub.execute_input":"2022-05-16T20:14:47.089387Z","iopub.status.idle":"2022-05-16T20:14:48.399729Z","shell.execute_reply.started":"2022-05-16T20:14:47.089361Z","shell.execute_reply":"2022-05-16T20:14:48.398883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Восьмая модель","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 35) \n        self.hidden_fc1 = nn.Linear(35, 15) \n\n        self.output_fc = nn.Linear(15, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_2) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:48.400977Z","iopub.execute_input":"2022-05-16T20:14:48.401187Z","iopub.status.idle":"2022-05-16T20:14:49.244199Z","shell.execute_reply.started":"2022-05-16T20:14:48.401162Z","shell.execute_reply":"2022-05-16T20:14:49.243397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Тесты на лучшей модели","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 30) \n        self.hidden_fc2 = nn.Linear(30, 20)\n        self.hidden_fc3 = nn.Linear(20, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        # x = [batch size, height, width] \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        # x = [batch size, height * width] \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        # h_1 = [batch size, 5] \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        h_4 = torch.tanh(self.hidden_fc3(h_3))\n \n        # h_2 = [batch size, 3] \n \n        y_pred = self.output_fc(h_4) \n \n        # y_pred = [batch size, output dim] \n \n        return y_pred\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)\n\nnum_epochs = 100\n\n\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n#ax.set_xticklabels('', size=10)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\ny_train_predict = scaler.inverse_transform(y_train_pred.detach().numpy().reshape(-1, 1))\ny_train_target = scaler.inverse_transform(y_train.detach().numpy().reshape(-1, 1))\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(y_train_target, y_train_predict))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntrainScore = mean_absolute_percentage_error(y_train_target, y_train_predict)\nprint('Train Score: %.2f MAPE' % (trainScore))\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:49.245861Z","iopub.execute_input":"2022-05-16T20:14:49.246311Z","iopub.status.idle":"2022-05-16T20:14:50.402093Z","shell.execute_reply.started":"2022-05-16T20:14:49.246268Z","shell.execute_reply":"2022-05-16T20:14:50.401112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Изменяем глобальные параметры, например возьмем другую станцию и проверим ее на обученной модели","metadata":{}},{"cell_type":"code","source":"del X_\ndel X_train\ndel X_test\ndel y_train\ndel y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:14:50.403552Z","iopub.execute_input":"2022-05-16T20:14:50.403781Z","iopub.status.idle":"2022-05-16T20:14:50.409461Z","shell.execute_reply.started":"2022-05-16T20:14:50.403752Z","shell.execute_reply":"2022-05-16T20:14:50.408568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STATION = 36093002\naround = 10","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:06:03.87388Z","iopub.execute_input":"2022-05-17T11:06:03.874687Z","iopub.status.idle":"2022-05-17T11:06:03.878542Z","shell.execute_reply.started":"2022-05-17T11:06:03.874651Z","shell.execute_reply":"2022-05-17T11:06:03.877779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(2016)+'.csv'\ndf = pd.read_csv(fname)\n\n# this dataframe we need to get closest stations from STATION\nnew_df = df.drop(['height_sta','date','dd','ff','precip','hu','td','t','psl'],axis=1)\\\n    .drop_duplicates('number_sta').reset_index()\n    \nlat = new_df[new_df.number_sta==STATION].lat.values[0]\nlon = new_df[new_df.number_sta==STATION].lon.values[0]\n    \n    \n# Arrays of closest stations\nneighbours = np.zeros(around)\nneighbours[0] = STATION\n    \nfor station in range(1,around):\n    for i in range(0,new_df.shape[0]):\n        if new_df.loc[i]['number_sta'] not in neighbours:\n            currdist = np.abs(lat - new_df.loc[i].lat) + np.abs(lon-new_df.loc[i].lon)\n            if(mindist > currdist):\n                mindist = currdist\n                index = i\n    neighbours[station]=new_df.loc[index]['number_sta']\n    mindist=10\n    \ndel new_df\n\ndel df\n\n\nweather = pd.DataFrame()\nfor year in years:\n    fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(year)+'.csv'\n    df = pd.read_csv(fname)\n    \n    # Getting source data from stations in neighbours\n    for i in range(0,around):\n        dataframe = df[(df['number_sta'] == int(neighbours[i]))]\n        weather = weather.append(dataframe,ignore_index = True)\n    \n    del df\n    \n    del dataframe","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:15:13.71424Z","iopub.execute_input":"2022-05-16T20:15:13.714453Z","iopub.status.idle":"2022-05-16T20:16:48.596736Z","shell.execute_reply.started":"2022-05-16T20:15:13.714427Z","shell.execute_reply":"2022-05-16T20:16:48.59566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.date = pd.to_datetime(weather.date)\nweather = weather.sort_values('number_sta').reset_index().drop('index',axis=1)\nweather = weather.fillna(method = 'bfill')\nweather = weather.sort_values('date').reset_index().drop('index',axis=1)\n\ndataset = weather[weather['date']<'2017-09-01']\ndataset = dataset[dataset['date']>'2017-07-01']\n\ndel weather\n\nlat = dataset[dataset['number_sta']==STATION]['lat'].unique()[0]\nlon = dataset[dataset['number_sta']==STATION]['lon'].unique()[0]\n\ndataset['lat'] = dataset['lat']-lat\ndataset['lon'] = dataset['lon']-lon\n\ndataset['year'] = dataset.date.dt.year\ndataset['yday'] = dataset.date.dt.dayofyear\ndataset['hour'] = dataset.date.dt.hour\ndataset['minute'] = dataset.date.dt.minute\n\ndataset = dataset.set_index('date')\ndataset = dataset.fillna(method = 'bfill')\n\ndataset['dd'] = scaler.fit_transform(dataset['dd'].values.reshape(-1,1))\ndataset['ff'] = scaler.fit_transform(dataset['ff'].values.reshape(-1,1))\ndataset['precip'] = scaler.fit_transform(dataset['precip'].values.reshape(-1,1))\ndataset['hu'] = scaler.fit_transform(dataset['hu'].values.reshape(-1,1))\ndataset['td'] = scaler.fit_transform(dataset['td'].values.reshape(-1,1))\ndataset['psl'] = scaler.fit_transform(dataset['psl'].values.reshape(-1,1))\ndataset['t'] = scaler.fit_transform(dataset['t'].values.reshape(-1,1))\n\nX,y = make_tensors(dataset,'t')\n\n\ncolumns = len(X[0][0])\nX_ = np.empty((0,(around-1)*columns),dtype='f')\nindex = []\nfor i in range(len(X)):\n    if len([a for b in X[i] for a in b]) == (around-1)*columns and i!=len(X)-1:\n        X_= np.append(X_,[[a for b in X[i] for a in b]],axis=0)\n    else:\n        index.append(i)\n\nindex.pop(len(index)-1)\n\ny=np.delete(y,index,None)\ny = np.delete(y,len(y)-1,None)\n\ndel dataset\n\ny_ = [[] for k in range(len(y))]\nfor i in range(len(y)):\n    y_[i] = [y[i]]\nprint(len(y_))\ny = y_\n\ndel X\n\nX = X_[:]\ny = y[:]\n\nX_test = torch.from_numpy(X).type(torch.Tensor)\ny_test = torch.from_numpy(np.array(y)).type(torch.Tensor)\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n# calculate root mean squared error\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-16T20:16:48.59849Z","iopub.execute_input":"2022-05-16T20:16:48.598758Z","iopub.status.idle":"2022-05-16T20:17:25.399586Z","shell.execute_reply.started":"2022-05-16T20:16:48.598729Z","shell.execute_reply":"2022-05-16T20:17:25.398691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Смещение прогноза на 30 минут, а не в текущий момент как до этого","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import time\n# from sklearn.preprocessing import MinMaxScaler\n# scaler = MinMaxScaler(feature_range=(-1, 1))\n# import numpy as np\n# years = [2016,2017,2018]\n# zone = 'NW'\n# mindist = 10\n\n# def make_tensors(table,predicted_par):\n    \n#     data = []\n#     target = []\n\n#     periods = table.index.unique().astype('str')\n    \n#     label = table[table.number_sta==STATION][predicted_par]\n#     target = label.values.tolist()\n    \n#     #new_table = table.loc[table['number_sta'] != STATION].drop(['td','lat','lon','height_sta','precip','dd','ff','hu','psl','yday','year','hour','minute','number_sta'],axis=1)\n#     new_table = table.loc[table['number_sta'] != STATION].drop(['height_sta','year','yday','hour','minute','number_sta'],axis=1)\n    \n#     for period in periods:\n#         if period in label:\n#             data.append(new_table[period:period].values.tolist())\n\n#     return data,target\n\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# import plotly.express as px\n# import plotly.graph_objects as go\n\n\n# class MLP(nn.Module): \n#     def __init__(self, input_dim, output_dim): \n#         super().__init__() \n \n#         self.input_fc = nn.Linear(input_dim, 50) \n#         self.hidden_fc1 = nn.Linear(50, 25) \n#         self.hidden_fc2 = nn.Linear(25, 10)\n#         self.output_fc = nn.Linear(10, output_dim) \n \n#     def forward(self, x): \n \n#         batch_size = x.shape[0] \n \n#         x = x.view(batch_size, -1) \n \n#         h_1 = torch.tanh(self.input_fc(x)) \n \n#         h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n#         h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n#         y_pred = self.output_fc(h_3) \n \n#         return y_pred\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:31:45.26769Z","iopub.execute_input":"2022-05-19T18:31:45.268634Z","iopub.status.idle":"2022-05-19T18:31:45.287515Z","shell.execute_reply.started":"2022-05-19T18:31:45.268559Z","shell.execute_reply":"2022-05-19T18:31:45.286702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 25) \n        self.hidden_fc2 = nn.Linear(25, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        y_pred = self.output_fc(h_3) \n \n        return y_pred\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STATION = 14066001\naround = 15","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:31:45.803408Z","iopub.execute_input":"2022-05-19T18:31:45.8037Z","iopub.status.idle":"2022-05-19T18:31:45.807874Z","shell.execute_reply.started":"2022-05-19T18:31:45.80367Z","shell.execute_reply":"2022-05-19T18:31:45.807056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timepredict = (around-1)*5","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:31:46.344953Z","iopub.execute_input":"2022-05-19T18:31:46.345469Z","iopub.status.idle":"2022-05-19T18:31:46.350001Z","shell.execute_reply.started":"2022-05-19T18:31:46.345425Z","shell.execute_reply":"2022-05-19T18:31:46.34887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(2016)+'.csv'\ndf = pd.read_csv(fname)\n\n# this dataframe we need to get closest stations from STATION\nnew_df = df.drop(['height_sta','date','dd','ff','precip','hu','td','t','psl'],axis=1)\\\n    .drop_duplicates('number_sta').reset_index()\n    \nlat = new_df[new_df.number_sta==STATION].lat.values[0]\nlon = new_df[new_df.number_sta==STATION].lon.values[0]\n    \n    \n# Arrays of closest stations\nneighbours= np.zeros(around)\nneighbours[0] = STATION\n    \nfor station in range(1,around):\n    for i in range(0,new_df.shape[0]):\n        if new_df.loc[i]['number_sta'] not in neighbours:\n            currdist = np.abs(lat - new_df.loc[i].lat) + np.abs(lon-new_df.loc[i].lon)\n            if(mindist > currdist):\n                mindist = currdist\n                index = i\n    neighbours[station]=new_df.loc[index]['number_sta']\n    mindist=10\n    \ndel new_df\n\ndel df\n\n\nweather = pd.DataFrame()\nfor year in years:\n    fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(year)+'.csv'\n    df = pd.read_csv(fname)\n    \n    # Getting source data from stations in neighbours\n    for i in range(0,around):\n        dataframe = df[(df['number_sta'] == int(neighbours[i]))]\n        weather = weather.append(dataframe,ignore_index = True)\n    \n    del df\n    \n    del dataframe","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:31:46.962684Z","iopub.execute_input":"2022-05-19T18:31:46.963263Z","iopub.status.idle":"2022-05-19T18:33:57.844138Z","shell.execute_reply.started":"2022-05-19T18:31:46.963221Z","shell.execute_reply":"2022-05-19T18:33:57.843197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.date = pd.to_datetime(weather.date)\nweather = weather.sort_values('number_sta').reset_index().drop('index',axis=1)\nweather = weather.fillna(method = 'bfill')\nweather = weather.sort_values('date').reset_index().drop('index',axis=1)\n\ndataset = weather[weather['date']<'2019-01-01']","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:33:57.847899Z","iopub.execute_input":"2022-05-19T18:33:57.848695Z","iopub.status.idle":"2022-05-19T18:34:00.226789Z","shell.execute_reply.started":"2022-05-19T18:33:57.848636Z","shell.execute_reply":"2022-05-19T18:34:00.225692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del weather\n\nlat = dataset[dataset['number_sta']==STATION]['lat'].unique()[0]\nlon = dataset[dataset['number_sta']==STATION]['lon'].unique()[0]\n\ndataset['lat'] = dataset['lat']-lat\ndataset['lon'] = dataset['lon']-lon\n\ndataset['year'] = dataset.date.dt.year\ndataset['yday'] = dataset.date.dt.dayofyear\ndataset['hour'] = dataset.date.dt.hour\ndataset['minute'] = dataset.date.dt.minute\n\ndataset = dataset.set_index('date')\ndataset = dataset.fillna(method = 'bfill')\n\ndataset['dd'] = scaler.fit_transform(dataset['dd'].values.reshape(-1,1))\ndataset['ff'] = scaler.fit_transform(dataset['ff'].values.reshape(-1,1))\ndataset['precip'] = scaler.fit_transform(dataset['precip'].values.reshape(-1,1))\ndataset['hu'] = scaler.fit_transform(dataset['hu'].values.reshape(-1,1))\ndataset['td'] = scaler.fit_transform(dataset['td'].values.reshape(-1,1))\ndataset['psl'] = scaler.fit_transform(dataset['psl'].values.reshape(-1,1))\ndataset['t'] = scaler.fit_transform(dataset['t'].values.reshape(-1,1))\n\nX,y = make_tensors(dataset,'t')\n\n\ncolumns = len(X[0][0])\nX_ = np.empty((0,(around-1)*columns),dtype='f')\nindex = []\nfor i in range(len(X)):\n    if len([a for b in X[i] for a in b]) == (around-1)*columns and i!=len(X)-1:\n        X_= np.append(X_,[[a for b in X[i] for a in b]],axis=0)\n    else:\n        index.append(i)\n\nindex.pop(len(index)-1)\n\ny=np.delete(y,index,None)\ny = np.delete(y,len(y)-1,None)\n\ndel dataset\n\ny_ = [[] for k in range(len(y))]\nfor i in range(len(y)):\n    y_[i] = [y[i]]\nprint(len(y_))\ny = y_\n\ndel X\n\nX_train = X_[0:int(len(X_)*0.9)]\nX_test = X_[int(len(X_)*0.9):len(X_)-int(timepredict/(around-1))]\ny_train = y[int(timepredict/(around-1)):int(len(y)*0.9)+int(timepredict/(around-1))]\ny_test = y[int(len(y)*0.9)+int(timepredict/(around-1)):]\n\nX_test = torch.from_numpy(X_test).type(torch.Tensor)\ny_test = torch.from_numpy(np.array(y_test)).type(torch.Tensor)\nX_train = torch.from_numpy(X_train).type(torch.Tensor)\ny_train = torch.from_numpy(np.array(y_train)).type(torch.Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T18:34:00.230968Z","iopub.execute_input":"2022-05-19T18:34:00.231476Z","iopub.status.idle":"2022-05-19T20:00:05.49732Z","shell.execute_reply.started":"2022-05-19T18:34:00.231434Z","shell.execute_reply":"2022-05-19T20:00:05.496555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:00:05.499531Z","iopub.execute_input":"2022-05-19T20:00:05.499906Z","iopub.status.idle":"2022-05-19T20:00:05.545656Z","shell.execute_reply.started":"2022-05-19T20:00:05.499863Z","shell.execute_reply":"2022-05-19T20:00:05.544975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 60\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:00:05.546981Z","iopub.execute_input":"2022-05-19T20:00:05.547407Z","iopub.status.idle":"2022-05-19T20:00:26.2564Z","shell.execute_reply.started":"2022-05-19T20:00:05.54737Z","shell.execute_reply":"2022-05-19T20:00:26.255422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\n\nax = sns.lineplot(data=hist, color='royalblue')\nax.set_xlabel(\"Epoch\", size = 14)\nax.set_ylabel(\"Loss\", size = 14)\nax.set_title(\"Training Loss\", size = 14, fontweight='bold')\nfig.set_figheight(6)\nfig.set_figwidth(16)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:00:26.257984Z","iopub.execute_input":"2022-05-19T20:00:26.258673Z","iopub.status.idle":"2022-05-19T20:00:26.52354Z","shell.execute_reply.started":"2022-05-19T20:00:26.258627Z","shell.execute_reply":"2022-05-19T20:00:26.522563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\n# calculate root mean squared error\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:36:25.703873Z","iopub.execute_input":"2022-05-19T20:36:25.70495Z","iopub.status.idle":"2022-05-19T20:36:28.786914Z","shell.execute_reply.started":"2022-05-19T20:36:25.704884Z","shell.execute_reply":"2022-05-19T20:36:28.78623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Прогноз погоды на 2 часа","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport time\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n\nscaler = MinMaxScaler(feature_range=(-1, 1))\nimport numpy as np\nyears = [2016,2017,2018]\nzone = 'NW'\nmindist = 10\n\ndef make_tensors(table,predicted_par):\n    \n    data = []\n    target = []\n\n    periods = table.index.unique().astype('str')\n    \n    label = table[table.number_sta==STATION][predicted_par]\n    target = label.values.tolist()\n    \n    #new_table = table.loc[table['number_sta'] != STATION].drop(['td','lat','lon','height_sta','precip','dd','ff','hu','psl','yday','year','hour','minute','number_sta'],axis=1)\n    new_table = table.loc[table['number_sta'] != STATION].drop(['height_sta','year','yday','hour','minute','number_sta'],axis=1)\n    \n    for period in periods:\n        if period in label:\n            data.append(new_table[period:period].values.tolist())\n\n    return data,target","metadata":{"execution":{"iopub.status.busy":"2022-06-21T11:47:29.678629Z","iopub.execute_input":"2022-06-21T11:47:29.679035Z","iopub.status.idle":"2022-06-21T11:47:33.136436Z","shell.execute_reply.started":"2022-06-21T11:47:29.678933Z","shell.execute_reply":"2022-06-21T11:47:33.135501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLP(nn.Module): \n    def __init__(self, input_dim, output_dim): \n        super().__init__() \n \n        self.input_fc = nn.Linear(input_dim, 50) \n        self.hidden_fc1 = nn.Linear(50, 25) \n        self.hidden_fc2 = nn.Linear(25, 10)\n        self.output_fc = nn.Linear(10, output_dim) \n \n    def forward(self, x): \n \n        batch_size = x.shape[0] \n \n        x = x.view(batch_size, -1) \n \n        h_1 = torch.tanh(self.input_fc(x)) \n \n        h_2 = torch.tanh(self.hidden_fc1(h_1)) \n    \n        h_3 = torch.tanh(self.hidden_fc2(h_2)) \n        \n        y_pred = self.output_fc(h_3) \n \n        return y_pred\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T11:47:38.606633Z","iopub.execute_input":"2022-06-21T11:47:38.60698Z","iopub.status.idle":"2022-06-21T11:47:38.614457Z","shell.execute_reply.started":"2022-06-21T11:47:38.606941Z","shell.execute_reply":"2022-06-21T11:47:38.613519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STATION = 14066001\naround = 15\ntimepredict = (around-1)*20\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T11:47:45.914779Z","iopub.execute_input":"2022-06-21T11:47:45.915156Z","iopub.status.idle":"2022-06-21T11:47:45.920141Z","shell.execute_reply.started":"2022-06-21T11:47:45.915114Z","shell.execute_reply":"2022-06-21T11:47:45.919065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(2016)+'.csv'\ndf = pd.read_csv(fname)\n\n# this dataframe we need to get closest stations from STATION\nnew_df = df.drop(['height_sta','date','dd','ff','precip','hu','td','t','psl'],axis=1)\\\n    .drop_duplicates('number_sta').reset_index()\n    \nlat = new_df[new_df.number_sta==STATION].lat.values[0]\nlon = new_df[new_df.number_sta==STATION].lon.values[0]\n    \n    \n# Arrays of closest stations\nneighbours= np.zeros(around)\nneighbours[0] = STATION\n    \nfor station in range(1,around):\n    for i in range(0,new_df.shape[0]):\n        if new_df.loc[i]['number_sta'] not in neighbours:\n            currdist = np.abs(lat - new_df.loc[i].lat) + np.abs(lon-new_df.loc[i].lon)\n            if(mindist > currdist):\n                mindist = currdist\n                index = i\n    neighbours[station]=new_df.loc[index]['number_sta']\n    mindist=10\n    \ndel new_df\n\ndel df\n\n\nweather = pd.DataFrame()\nfor year in years:\n    fname = '/kaggle/input/meteonet/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations/'+zone+\\\n    '_Ground_Stations_'+str(year)+'.csv'\n    df = pd.read_csv(fname)\n    \n    # Getting source data from stations in neighbours\n    for i in range(0,around):\n        dataframe = df[(df['number_sta'] == int(neighbours[i]))]\n        weather = weather.append(dataframe,ignore_index = True)\n    \n    del df\n    \n    del dataframe\n    \nweather.date = pd.to_datetime(weather.date)\nweather = weather.sort_values('number_sta').reset_index().drop('index',axis=1)\nweather = weather.fillna(method = 'bfill')\nweather = weather.sort_values('date').reset_index().drop('index',axis=1)\n\ndataset = weather[weather['date']<'2019-01-01']\n\n\ndel weather\n\nlat = dataset[dataset['number_sta']==STATION]['lat'].unique()[0]\nlon = dataset[dataset['number_sta']==STATION]['lon'].unique()[0]\n\ndataset['lat'] = dataset['lat']-lat\ndataset['lon'] = dataset['lon']-lon\n\ndataset['year'] = dataset.date.dt.year\ndataset['yday'] = dataset.date.dt.dayofyear\ndataset['hour'] = dataset.date.dt.hour\ndataset['minute'] = dataset.date.dt.minute\n\ndataset = dataset.set_index('date')\ndataset = dataset.fillna(method = 'bfill')\n\ndataset['dd'] = scaler.fit_transform(dataset['dd'].values.reshape(-1,1))\ndataset['ff'] = scaler.fit_transform(dataset['ff'].values.reshape(-1,1))\ndataset['precip'] = scaler.fit_transform(dataset['precip'].values.reshape(-1,1))\ndataset['hu'] = scaler.fit_transform(dataset['hu'].values.reshape(-1,1))\ndataset['td'] = scaler.fit_transform(dataset['td'].values.reshape(-1,1))\ndataset['psl'] = scaler.fit_transform(dataset['psl'].values.reshape(-1,1))\ndataset['t'] = scaler.fit_transform(dataset['t'].values.reshape(-1,1))\n\nX,y = make_tensors(dataset,'t')\n\n\ncolumns = len(X[0][0])\nX_ = np.empty((0,(around-1)*columns),dtype='f')\nindex = []\nfor i in range(len(X)):\n    if len([a for b in X[i] for a in b]) == (around-1)*columns and i!=len(X)-1:\n        X_= np.append(X_,[[a for b in X[i] for a in b]],axis=0)\n    else:\n        index.append(i)\n\nindex.pop(len(index)-1)\n\ny=np.delete(y,index,None)\ny = np.delete(y,len(y)-1,None)\n\ndel dataset\n\ny_ = [[] for k in range(len(y))]\nfor i in range(len(y)):\n    y_[i] = [y[i]]\nprint(len(y_))\ny = y_\n\ndel X\n\nX_train = X_[0:int(len(X_)*0.9)]\nX_test = X_[int(len(X_)*0.9):len(X_)-int(timepredict/(around-1))]\ny_train = y[int(timepredict/(around-1)):int(len(y)*0.9)+int(timepredict/(around-1))]\ny_test = y[int(len(y)*0.9)+int(timepredict/(around-1)):]\n\nX_test = torch.from_numpy(X_test).type(torch.Tensor)\ny_test = torch.from_numpy(np.array(y_test)).type(torch.Tensor)\nX_train = torch.from_numpy(X_train).type(torch.Tensor)\ny_train = torch.from_numpy(np.array(y_train)).type(torch.Tensor)\n\n\nmodel = MLP(input_dim=X_train[0].shape[0], output_dim=len(y_train[0]))\ncriterion = torch.nn.MSELoss(reduction='mean')\noptimiser = torch.optim.Adam(model.parameters(), lr=0.03)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T11:47:46.754256Z","iopub.execute_input":"2022-06-21T11:47:46.754605Z","iopub.status.idle":"2022-06-21T13:41:30.028122Z","shell.execute_reply.started":"2022-06-21T11:47:46.754565Z","shell.execute_reply":"2022-06-21T13:41:30.027164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 150\nhist = np.zeros(num_epochs)\nstart_time = time.time()\n\nfor epoch in range(num_epochs):\n    y_train_pred = model(X_train)\n    #print(y_train_pred)\n    loss = criterion(y_train_pred, y_train)\n    print(\"Epoch \", epoch, \"MSE: \", loss.item(), \" Time: \",time.time()-start_time)\n    hist[epoch] = loss.item()\n    optimiser.zero_grad()\n    loss.backward()\n    optimiser.step()\n    \ntraining_time = time.time()-start_time\nprint(\"Training time: {}\".format(training_time))\n\n\nfig = plt.figure()\nfig.subplots_adjust(hspace=0.2, wspace=0.2)\n\nax = sns.lineplot(data=hist, color='royalblue')\nax.set_xlabel(\"Epoch\", size = 14)\nax.set_ylabel(\"Loss\", size = 14)\nax.set_title(\"Training Loss\", size = 14, fontweight='bold')\nfig.set_figheight(6)\nfig.set_figwidth(16)\n\n\n\ny_test_pred = model(X_test)\n\ny_test_predict = scaler.inverse_transform(y_test_pred.detach().numpy().reshape(-1, 1))\ny_test_target = scaler.inverse_transform(y_test.detach().numpy().reshape(-1, 1))\n\ny_test_predict = pd.DataFrame(y_test_predict)\ny_test_target = pd.DataFrame(y_test_target)\n\n\nfig = plt.figure()\nax = sns.lineplot(x = y_test_target.index, y = y_test_target[0], label=\"Data\", color='tomato')\nax = sns.lineplot(x = y_test_predict.index, y = y_test_predict[0], label=\"Prediction\", color='royalblue')\nax.set_title('Temperature', size = 14, fontweight='bold')\nax.set_xlabel(\"Records\", size = 14)\nax.set_ylabel(\"Kelvins\", size = 14)\nfig.set_figheight(6)\nfig.set_figwidth(16)\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(go.Scatter(x=y_test_target.index, y=y_test_target[0],\n                    mode='lines',\n                    name='Actual Value')))\nfig.add_trace(go.Scatter(x=y_test_predict.index, y=y_test_predict[0],\n                    mode='lines',\n                    name='Test prediction'))\n\nfig.update_layout(\n    xaxis=dict(\n        showline=True,\n        showgrid=True,\n        showticklabels=False,\n        linecolor='white',\n        linewidth=2\n    ),\n    yaxis=dict(\n        title_text='Temperature (Kelvins)',\n        titlefont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n        showline=True,\n        showgrid=True,\n        showticklabels=True,\n        linecolor='white',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Rockwell',\n            size=12,\n            color='white',\n        ),\n    ),\n    showlegend=True,\n    template = 'plotly_dark'\n\n)\nannotations = []\nannotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,\n                              xanchor='left', yanchor='bottom',\n                              text='Results (MLP)',\n                              font=dict(family='Rockwell',\n                                        size=26,\n                                        color='white'),\n                              showarrow=False))\nfig.update_layout(annotations=annotations)\n\nfig.show()\n\n\n# calculate root mean squared error\ntestScore = math.sqrt(mean_squared_error(y_test_target, y_test_predict))\nprint('Test Score: %.2f RMSE' % (testScore))\n\ntestScore = mean_absolute_percentage_error(y_test_target, y_test_predict)\nprint('Test Score: %.2f MAPE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2022-06-21T13:41:30.030932Z","iopub.execute_input":"2022-06-21T13:41:30.031777Z","iopub.status.idle":"2022-06-21T13:42:06.794703Z","shell.execute_reply.started":"2022-06-21T13:41:30.031719Z","shell.execute_reply":"2022-06-21T13:42:06.794021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}